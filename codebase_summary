{
  "cmd/consumer/main.go": "- File Path: `cmd/consumer/main.go`\n- High-Level Purpose: This file is the entry point for the log processing consumer worker. It initializes the application's configuration, logger, and connections to Redis (for buffering) and PostgreSQL (for persistent storage), then starts a continuous loop to read log events from Redis, process them, and write them to PostgreSQL. It also handles graceful shutdown.\n- Definitions in the File:\n  - Constants:\n    - `consumerGroup` (string): \"log-processors\". The name of the Redis consumer group.\n    - `processingInterval` (time.Duration): `1 * time.Second`. The interval at which the consumer attempts to process log batches.\n  - Functions:\n    - `main()`: Public function.\n      - Description: The main function orchestrates the consumer worker. It loads configuration, initializes a structured logger, establishes connections to Redis and PostgreSQL, and sets up signal handling for graceful shutdown. It then instantiates the Redis-based `LogRepository` (for buffering), the PostgreSQL-based `LogRepository` (for sinking), and the `ProcessLogsUseCase`. Finally, it enters a ticker-driven loop to repeatedly call `ProcessBatch` on the use case until a `SIGINT` or `SIGTERM` signal is received, at which point it initiates a graceful shutdown.\n- Notable Patterns or Logic:\n  - Application entry point and bootstrap.\n  - Dependency Injection/Composition Root for assembling application components.\n  - Graceful shutdown mechanism using `context.WithCancel` and `os.Signal` handling.\n  - Consumer pattern: continuously polling a message queue (Redis Streams) and processing batches.\n",
  "cmd/ingest/main.go": "- File Path: `cmd/ingest/main.go`\n- High-Level Purpose: This file serves as the entry point for the log ingest gateway service. It orchestrates the application startup, including configuration loading, dependency initialization (database, Redis), HTTP server setup, and graceful shutdown.\n- Definitions in the File:\n  - Functions:\n    - `main()`: Public function.\n      - Description: The main function of the ingest gateway. It loads application configuration, initializes a structured logger, establishes connections to PostgreSQL and Redis, and instantiates various components: `APIKeyRepository`, `LogRepository`, PII `Redactor`, and `IngestLogUseCase`. It then sets up and starts an HTTP server using the configured router and handles graceful shutdown upon receiving `SIGINT` or `SIGTERM` signals.\n- Notable Patterns or Logic:\n  - Application entry point and bootstrap.\n  - Dependency Injection/Composition Root for assembling the application components.\n  - Graceful shutdown mechanism for the HTTP server.\n  - Database and Redis client initialization.\n",
  "go.mod": "- File Path: `go.mod`\n- High-Level Purpose: This file defines the Go module path and manages the direct and indirect dependencies required for the `github.com/user/log-ingestor` project.\n- Definitions in the File:\n  - Module: `github.com/user/log-ingestor`\n  - Go Version: `1.21`\n  - Direct Dependencies:\n    - `github.com/caarlos0/env/v10 v10.0.0`: Used for parsing environment variables into Go structs.\n    - `github.com/google/uuid v1.6.0`: Used for generating universally unique identifiers.\n    - `github.com/joho/godotenv v1.5.1`: Used for loading environment variables from `.env` files.\n    - `github.com/lib/pq v1.10.9`: PostgreSQL database driver.\n    - `github.com/redis/go-redis/v9 v9.5.1`: Redis client library.\n  - Indirect Dependencies:\n    - `github.com/cespare/xxhash/v2 v2.2.0`\n    - `github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f`\n- Notable Patterns or Logic:\n  - Go Module definition for dependency management.\n",
  "internal/adapter/api/handler/ingest_handler.go": "- File Path: `internal/adapter/api/handler/ingest_handler.go`\n- High-Level Purpose: This file defines an HTTP handler responsible for receiving and processing incoming log ingestion requests, supporting both single JSON and NDJSON (Newline Delimited JSON) formats.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `IngestHandler` (struct): An HTTP handler that processes log ingestion requests.\n      - Fields:\n        - `useCase` (`*usecase.IngestLogUseCase`): The use case responsible for the business logic of log ingestion.\n        - `logger` (`*slog.Logger`): A structured logger instance.\n        - `maxEventSize` (`int64`): The maximum allowed size for an incoming request body.\n  - Functions:\n    - `NewIngestHandler(uc *usecase.IngestLogUseCase, logger *slog.Logger, maxEventSize int64) *IngestHandler`: Public function.\n      - Description: Constructor for `IngestHandler`, initializing it with the ingest use case, logger, and the maximum event size.\n    - `(*IngestHandler) ServeHTTP(w http.ResponseWriter, r *http.Request)`: Public method.\n      - Description: Implements the `http.Handler` interface. It validates the request method (must be POST), enforces a maximum request body size, and dispatches the request to either `handleSingleJSON` or `handleNDJSON` based on the `Content-Type` header. It handles various HTTP errors such as unsupported media type, payload too large, and bad requests.\n    - `(*IngestHandler) handleSingleJSON(ctx context.Context, body io.Reader) error`: Internal method.\n      - Description: Reads a single JSON log event from the request body, unmarshals it into a `domain.LogEvent`, stores the raw event payload, and then passes it to the `IngestLogUseCase` for processing.\n    - `(*IngestHandler) handleNDJSON(ctx context.Context, body io.Reader) error`: Internal method.\n      - Description: Reads the request body line by line, treating each line as a separate JSON log event. It unmarshals each line, stores the raw event, and calls the `IngestLogUseCase` for each. It logs warnings for unmarshalling errors and errors for ingestion failures, but continues processing subsequent lines.\n- Notable Patterns or Logic:\n  - HTTP Handler implementation (`http.Handler` interface).\n  - Content-Type based request routing.\n  - Request body size limiting using `http.MaxBytesReader`.\n  - Processing of Newline Delimited JSON (NDJSON) streams.\n",
  "internal/adapter/api/middleware/auth.go": "- File Path: `internal/adapter/api/middleware/auth.go`\n- High-Level Purpose: This file defines an HTTP middleware for authenticating incoming requests by validating an API key provided in the `X-API-Key` header.\n- Definitions in the File:\n  - Constants:\n    - `APIKeyHeader` (string): \"X-API-Key\". Specifies the HTTP header name for the API key.\n  - Functions:\n    - `Auth(repo domain.APIKeyRepository, logger *slog.Logger) func(http.Handler) http.Handler`: Public function.\n      - Description: A middleware factory that returns an `http.Handler` function. It extracts the API key from the request header, uses the provided `APIKeyRepository` to validate it, and either allows the request to proceed or responds with an `Unauthorized` or `Internal Server Error` status.\n- Notable Patterns or Logic:\n  - HTTP Middleware pattern for request interception and processing.\n  - Dependency injection for the API key repository and logger.\n",
  "internal/adapter/api/router.go": "- File Path: `internal/adapter/api/router.go`\n- High-Level Purpose: This file is responsible for configuring and setting up the main HTTP router for the log ingest service, defining routes, associating them with handlers, and applying middleware.\n- Definitions in the File:\n  - Functions:\n    - `NewRouter(cfg *config.Config, logger *slog.Logger, apiKeyRepo domain.APIKeyRepository, ingestUseCase *usecase.IngestLogUseCase) http.Handler`: Public function.\n      - Description: Creates and configures an `http.ServeMux`. It initializes an `IngestHandler` and applies an `Auth` middleware (for API key validation) to the `POST /ingest` route. It also defines a simple `/health` check endpoint.\n- Notable Patterns or Logic:\n  - HTTP Router setup using `http.ServeMux`.\n  - Middleware chain application for request processing (e.g., authentication).\n  - Dependency injection for handlers and middleware.\n",
  "internal/adapter/pii/redactor.go": "- File Path: `internal/adapter/pii/redactor.go`\n- High-Level Purpose: This file defines a `Redactor` component responsible for identifying and replacing sensitive (PII) fields within the JSON `Metadata` of `LogEvent` objects with a placeholder.\n- Definitions in the File:\n  - Constants:\n    - `RedactedPlaceholder` (string): \"[REDACTED]\". The string used to replace redacted PII values.\n  - Classes / Structs / Interfaces:\n    - `Redactor` (struct): Manages the redaction of specified PII fields from log event metadata.\n      - Fields:\n        - `fieldsToRedact` (map[string]struct{}): A set of field names whose values should be redacted.\n        - `logger` (*slog.Logger): Structured logger instance.\n  - Functions:\n    - `NewRedactor(fields []string, logger *slog.Logger) *Redactor`: Public function.\n      - Description: Constructor for `Redactor`, initializing it with a list of field names to be redacted and a logger. It converts the list of fields into a map for efficient lookups.\n    - `(*Redactor) Redact(event *domain.LogEvent) error`: Public method.\n      - Description: Modifies the provided `LogEvent` in place. It unmarshals the `Metadata` field (expected to be JSON), iterates through the configured `fieldsToRedact`, and replaces any matching field values with `RedactedPlaceholder`. If any redaction occurs, it sets `event.PIIRedacted` to `true` and remarshals the modified metadata back into `event.Metadata`. It logs warnings or errors if JSON processing fails.\n- Notable Patterns or Logic:\n  - Data transformation/processing component.\n  - Dynamic JSON field manipulation using `encoding/json` for unmarshalling and marshalling.\n  - In-place modification of a domain object (`LogEvent`).",
  "internal/adapter/repository/postgres/apikey_repository.go": "- File Path: `internal/adapter/repository/postgres/apikey_repository.go`\n- High-Level Purpose: This file provides a PostgreSQL-backed implementation of the `domain.APIKeyRepository` interface, featuring an in-memory, time-based cache to optimize API key validation performance.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `cacheEntry` (struct): Represents a single entry in the API key cache.\n      - Fields:\n        - `isValid` (bool): Indicates if the API key is valid.\n        - `expiresAt` (time.Time): The timestamp when this cache entry expires.\n    - `APIKeyRepository` (struct): Implements `domain.APIKeyRepository` for PostgreSQL.\n      - Fields:\n        - `db` (*sql.DB): Database connection pool.\n        - `logger` (*slog.Logger): Structured logger instance.\n        - `cache` (map[string]cacheEntry): In-memory cache for API key validation results.\n        - `mu` (sync.RWMutex): Read-write mutex for thread-safe cache access.\n        - `cacheTTL` (time.Duration): Time-to-live for cache entries.\n  - Functions:\n    - `NewAPIKeyRepository(db *sql.DB, logger *slog.Logger, cacheTTL time.Duration) *APIKeyRepository`: Public function.\n      - Description: Constructor for `APIKeyRepository`, initializing it with a database connection, logger, and the desired cache TTL.\n    - `(*APIKeyRepository) IsValid(ctx context.Context, key string) (bool, error)`: Public method.\n      - Description: Checks if an API key is valid. It first attempts to retrieve the validation status from the in-memory cache. If the key is not found or the cache entry has expired, it queries the PostgreSQL database, updates the cache with the new validation status and expiration, and then returns the result. It uses a read-write mutex to ensure thread safety during cache operations.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for data access.\n  - Read-through caching mechanism with a configurable time-to-live (TTL).\n  - Concurrency control using `sync.RWMutex` for safe access to the shared cache.\n  - Database interaction using `database/sql` for PostgreSQL.\n",
  "internal/adapter/repository/postgres/log_repository.go": "- File Path: `internal/adapter/repository/postgres/log_repository.go`\n- High-Level Purpose: This file provides a PostgreSQL-backed implementation for the \"sink\" part of the `domain.LogRepository` interface, specifically designed for high-performance batch writing of log events using PostgreSQL's `COPY` protocol and idempotent upsert logic.\n- Definitions in the File:\n  - Constants:\n    - `logsTableName` (string): \"logs\". The name of the PostgreSQL table where logs are stored.\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (struct): Implements the `domain.LogRepository` interface for PostgreSQL.\n      - Fields:\n        - `db` (*sql.DB): Database connection pool.\n        - `logger` (*slog.Logger): Structured logger instance.\n  - Functions:\n    - `NewLogRepository(db *sql.DB, logger *slog.Logger) *LogRepository`: Public function.\n      - Description: Constructor for `LogRepository`, initializing it with a database connection and logger.\n    - `(*LogRepository) WriteLogBatch(ctx context.Context, events []domain.LogEvent) error`: Public method.\n      - Description: Writes a batch of log events to PostgreSQL. It uses a database transaction, creates a temporary table, and leverages `pq.CopyIn` for efficient bulk data transfer. After staging, it performs an `INSERT ... ON CONFLICT (event_id) DO UPDATE` (upsert) from the temporary table into the main `logs` table, ensuring idempotency.\n    - `errNotImplemented` (var): Internal variable.\n      - Description: An error indicating that a method is not implemented for this specific repository type.\n    - `(*LogRepository) BufferLog(ctx context.Context, event domain.LogEvent) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not responsible for buffering.\n    - `(*LogRepository) ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]domain.LogEvent, error)`: Public method.\n      - Description: Returns `nil, errNotImplemented` as this repository is not responsible for reading from a buffer.\n    - `(*LogRepository) AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not responsible for acknowledging buffered messages.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for data sinking.\n  - High-performance bulk inserts using PostgreSQL's `COPY` protocol.\n  - Idempotent upsert logic using `ON CONFLICT DO UPDATE`.\n  - Transaction management for batch operations.\n  - Partial interface implementation, indicating a specialized role (sink only).\n",
  "internal/adapter/repository/redis/log_repository.go": "- File Path: `internal/adapter/repository/redis/log_repository.go`\n- High-Level Purpose: This file provides a Redis Streams-backed implementation for the \"buffering\" part of the `domain.LogRepository` interface, enabling log events to be added to a stream, read in batches by consumer groups, and acknowledged upon successful processing.\n- Definitions in the File:\n  - Constants:\n    - `logStreamKey` (string): \"log_events\". The Redis Stream key used for log events.\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (struct): Implements the `domain.LogRepository` interface using Redis Streams.\n      - Fields:\n        - `client` (*redis.Client): Redis client instance.\n        - `logger` (*slog.Logger): Structured logger instance.\n  - Functions:\n    - `NewLogRepository(client *redis.Client, logger *slog.Logger, group, consumer string) (*LogRepository, error)`: Public function.\n      - Description: Constructor for `LogRepository`, initializing it with a Redis client and logger. It also calls `setupConsumerGroup` to ensure the necessary Redis stream and consumer group exist.\n    - `(*LogRepository) setupConsumerGroup(ctx context.Context, group string) error`: Internal method.\n      - Description: Creates the Redis stream (`logStreamKey`) and the specified consumer group if they do not already exist, using `XGroupCreateMkStream`. It specifically handles and ignores the \"BUSYGROUP\" error if the group already exists.\n    - `(*LogRepository) BufferLog(ctx context.Context, event domain.LogEvent) error`: Public method.\n      - Description: Marshals the `domain.LogEvent` into JSON and adds it to the `logStreamKey` Redis Stream using `XAdd`.\n    - `(*LogRepository) ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]domain.LogEvent, error)`: Public method.\n      - Description: Reads a batch of log events from the Redis Stream for a given consumer group and consumer using `XReadGroup`. It blocks for a short duration (`2 * time.Second`) if no new messages are available. It unmarshals the JSON payload of each message into a `domain.LogEvent` and attaches the Redis message ID.\n    - `(*LogRepository) AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Public method.\n      - Description: Acknowledges a list of message IDs in the Redis Stream for a given consumer group using `XAck`, marking them as successfully processed.\n    - `errNotImplemented` (var): Internal variable.\n      - Description: An error indicating that a method is not implemented for this specific repository type.\n    - `(*LogRepository) WriteLogBatch(ctx context.Context, events []domain.LogEvent) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not responsible for writing to a persistent sink.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for data buffering.\n  - Redis Streams for message queuing and consumer group management.\n  - JSON serialization/deserialization for storing and retrieving `LogEvent` objects.\n  - Partial interface implementation, indicating a specialized role (buffer only).\n",
  "internal/domain/log.go": "- File Path: `internal/domain/log.go`\n- High-Level Purpose: This file defines the `LogEvent` struct, which serves as the core data model for representing a single log event within the application's domain.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `LogEvent` (struct): Represents a single log event with various attributes.\n      - Fields:\n        - `ID` (string): Unique identifier for the log event.\n        - `ReceivedAt` (time.Time): Timestamp when the event was received by the system.\n        - `EventTime` (time.Time): Original timestamp of the event.\n        - `Source` (string): Origin of the log event (e.g., service name).\n        - `Level` (string): Log level (e.g., \"info\", \"error\").\n        - `Message` (string): The main log message.\n        - `Metadata` (json.RawMessage): Arbitrary JSON metadata associated with the event.\n        - `RawEvent` (json.RawMessage): The original raw payload of the event (not serialized for output).\n        - `PIIRedacted` (bool): Flag indicating if PII has been redacted from the event.\n        - `StreamMessageID` (string): Transient field for Redis Stream message ID (not serialized for output).\n- Notable Patterns or Logic:\n  - Domain model definition for log events.\n  - Use of `json.RawMessage` for flexible metadata storage.\n",
  "internal/domain/repository.go": "- File Path: `internal/domain/repository.go`\n- High-Level Purpose: This file defines several interfaces that abstract the contracts for various data access and storage operations within the application's domain, promoting loose coupling and testability.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (interface): Defines the contract for storing, retrieving, buffering, and acknowledging log events.\n      - Methods:\n        - `BufferLog(ctx context.Context, event LogEvent) error`: Adds a single log event to a buffer.\n        - `ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]LogEvent, error)`: Reads a batch of log events from a buffer for a specific consumer group.\n        - `WriteLogBatch(ctx context.Context, events []LogEvent) error`: Writes a batch of log events to a persistent storage.\n        - `AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Acknowledges processed log events in a buffer.\n    - `APIKeyRepository` (interface): Defines the contract for validating API keys.\n      - Methods:\n        - `IsValid(ctx context.Context, key string) (bool, error)`: Checks if a given API key is valid.\n    - `WALRepository` (interface): Defines the contract for a Write-Ahead Log (WAL) for failover buffering.\n      - Methods:\n        - `Write(ctx context.Context, event LogEvent) error`: Writes a log event to the WAL.\n        - `Replay(ctx context.Context, handler func(event LogEvent) error) error`: Replays events from the WAL.\n        - `Truncate(ctx context.Context) error`: Clears the WAL.\n- Notable Patterns or Logic:\n  - Repository pattern for abstracting data access.\n  - Interface segregation principle, defining distinct contracts for different data operations.\n",
  "internal/pkg/config/config.go": "- File Path: `internal/pkg/config/config.go`\n- High-Level Purpose: This file defines the application's configuration structure and provides a utility function to load these settings from environment variables, with support for `.env` files for local development.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `Config` (struct): Holds all application configuration parameters.\n      - Fields:\n        - `LogLevel` (string): The logging level (e.g., \"info\", \"debug\"). Default: \"info\".\n        - `MaxEventSize` (int64): Maximum allowed size for an incoming log event payload in bytes. Default: 1MB.\n        - `WALSegmentSize` (int64): Size of a Write-Ahead Log segment in bytes. Default: 100MB.\n        - `WALMaxDiskSize` (int64): Maximum total disk space for the WAL in bytes. Default: 1GB.\n        - `BackpressurePolicy` (string): Policy to apply when backpressure occurs. Default: \"block\".\n        - `RedisAddr` (string): Network address for the Redis server (required).\n        - `PostgresURL` (string): Connection string for the PostgreSQL database (required).\n        - `APIKeyCacheTTL` (time.Duration): Time-to-live for API key cache entries. Default: 5 minutes.\n        - `PIIRedactionFields` (string): Comma-separated list of field names to redact for PII. Default: \"email,password,credit_card,ssn\".\n        - `IngestServerAddr` (string): The address the ingest HTTP server will listen on. Default: \":8080\".\n  - Functions:\n    - `Load() (*Config, error)`: Public function.\n      - Description: Attempts to load environment variables from a `.env` file (for local development) and then parses these variables into a `Config` struct. Returns an error if any required environment variables are missing or parsing fails.\n- Notable Patterns or Logic:\n  - Centralized configuration management.\n  - Environment variable loading using `caarlos0/env`.\n  - Support for `.env` files using `joho/godotenv` for local development.",
  "internal/pkg/logger/logger.go": "- File Path: `internal/pkg/logger/logger.go`\n- High-Level Purpose: This file provides a utility function to create and configure a structured logger using Go's `slog` package.\n- Definitions in the File:\n  - Functions:\n    - `New(level string) *slog.Logger`: Public function.\n      - Description: Creates and returns a new `slog.Logger` instance. It configures the logger to output JSON format to standard output and sets the logging level based on the provided string (e.g., \"debug\", \"info\", \"warn\", \"error\"). Defaults to \"info\" if an unknown level is provided.\n- Notable Patterns or Logic:\n  - Centralized logger initialization.\n  - Structured logging setup using `slog`.\n",
  "internal/usecase/ingest_log.go": "- File Path: `internal/usecase/ingest_log.go`\n- High-Level Purpose: This file defines the `IngestLogUseCase`, which encapsulates the business logic for processing and buffering log events, including enrichment, PII redaction, and interaction with the log repository.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `IngestLogUseCase` (struct): Handles the core business logic for ingesting a log event.\n      - Fields:\n        - `repo` (`domain.LogRepository`): An interface for buffering log events.\n        - `redactor` (`*pii.Redactor`): A component responsible for redacting PII from log events.\n        - `logger` (`*slog.Logger`): A structured logger instance.\n  - Functions:\n    - `NewIngestLogUseCase(repo domain.LogRepository, redactor *pii.Redactor, logger *slog.Logger) *IngestLogUseCase`: Public function.\n      - Description: Constructor for `IngestLogUseCase`, initializing it with the necessary repository, PII redactor, and logger.\n    - `(*IngestLogUseCase) Ingest(ctx context.Context, event *domain.LogEvent) error`: Public method.\n      - Description: Validates, enriches, redacts, and buffers a log event. It sets `ReceivedAt` and generates an `ID` if missing, then calls the `pii.Redactor` to redact sensitive information. Finally, it uses the `domain.LogRepository` to buffer the processed event. It logs warnings for redaction failures and errors for buffering failures.\n- Notable Patterns or Logic:\n  - Use Case pattern for encapsulating business logic.\n  - Dependency injection for external services (repository, redactor, logger).\n  - In-place modification of the `domain.LogEvent` object.\n",
  "internal/usecase/process_logs.go": "- File Path: `internal/usecase/process_logs.go`\n- High-Level Purpose: This file defines the `ProcessLogsUseCase`, which encapsulates the business logic for orchestrating the flow of log events from a buffering repository (e.g., Redis) to a persistent sink repository (e.g., PostgreSQL), including retry mechanisms for sink operations.\n- Definitions in the File:\n  - Constants:\n    - `defaultBatchSize` (int): 1000. The number of log events to read in a single batch.\n    - `defaultRetryCount` (int): 3. The number of times to retry writing a batch to the sink.\n    - `defaultRetryBackoff` (time.Duration): `1 * time.Second`. The delay between retry attempts.\n  - Classes / Structs / Interfaces:\n    - `ProcessLogsUseCase` (struct): Orchestrates the processing of log events from buffer to sink.\n      - Fields:\n        - `bufferRepo` (`domain.LogRepository`): The repository responsible for reading buffered log events.\n        - `sinkRepo` (`domain.LogRepository`): The repository responsible for writing log events to persistent storage.\n        - `logger` (`*slog.Logger`): A structured logger instance.\n        - `group` (string): The consumer group name for the buffer.\n        - `consumer` (string): The unique consumer name for the buffer.\n  - Functions:\n    - `NewProcessLogsUseCase(bufferRepo, sinkRepo domain.LogRepository, logger *slog.Logger, group, consumer string) *ProcessLogsUseCase`: Public function.\n      - Description: Constructor for `ProcessLogsUseCase`, initializing it with the buffer and sink repositories, logger, and consumer group/name.\n    - `(*ProcessLogsUseCase) ProcessBatch(ctx context.Context) (int, error)`: Public method.\n      - Description: Reads a batch of log events from the `bufferRepo`. If events are found, it attempts to write them to the `sinkRepo` using a retry mechanism. Upon successful writing, it acknowledges the processed messages in the `bufferRepo`. It returns the count of processed events and any errors encountered during reading, writing, or acknowledging.\n    - `(*ProcessLogsUseCase) writeWithRetry(ctx context.Context, events []domain.LogEvent) error`: Internal method.\n      - Description: Attempts to write a batch of log events to the `sinkRepo` up to `defaultRetryCount` times. It introduces a `defaultRetryBackoff` delay between retries and respects the provided context for cancellation. It returns `nil` on the first successful write or the last error if all retries fail.\n- Notable Patterns or Logic:\n  - Use Case pattern for encapsulating business logic.\n  - Dependency Injection for `LogRepository` implementations (buffer and sink).\n  - Retry mechanism with fixed backoff for resilient sink operations.\n  - Clear separation of concerns between reading from a buffer and writing to a sink."
}