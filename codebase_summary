{
  "cmd/consumer/main.go": "- File Path: `cmd/consumer/main.go`\n- High-Level Purpose: This is the main entry point for the log processing consumer application. It initializes configuration, sets up logging, connects to Redis and PostgreSQL, creates the necessary repositories and use cases, and starts a loop to continuously process log batches from Redis Streams and write them to PostgreSQL.\n- Definitions in the File:\n  - Constants:\n    - `consumerGroup` (string): \"log-processors\". The name of the Redis consumer group this consumer belongs to.\n    - `processingInterval` (time.Duration): 1 * time.Second. The interval at which the consumer attempts to process a batch of logs.\n  - Functions:\n    - `main()`: Main function.\n      - Description:\n        1. Loads application configuration using `config.Load()`.\n        2. Initializes a structured logger using `logger.New()` and generates a unique consumer name.\n        3. Establishes connections to PostgreSQL (`database/sql`) and Redis (`github.com/redis/go-redis/v9`).\n        4. Creates `redisrepo.NewLogRepository` (as the buffer, without a WAL) and `postgres.NewLogRepository` (as the sink).\n        5. Instantiates `usecase.NewProcessLogsUseCase` with the configured repositories and retry settings.\n        6. Sets up a graceful shutdown mechanism using `context` and `os.Signal` (SIGINT, SIGTERM).\n        7. Enters a continuous loop, processing log batches at `processingInterval` until a shutdown signal is received or the context is canceled.\n- Notable Patterns or Logic:\n  - Application entry point (`main` function).\n  - Dependency injection for services (repositories, use cases).\n  - Graceful shutdown handling using `context` and `os.Signal`.\n  - Continuous polling loop for processing messages from a queue (Redis Stream).\n  - Separation of concerns: `main` orchestrates components, business logic is in `usecase`, data access in `repository`.\n",
  "cmd/ingest/main.go": "- File Path: `cmd/ingest/main.go`\n- High-Level Purpose: This is the main entry point for the log ingest service. It initializes configuration, sets up logging, connects to Redis and PostgreSQL, creates repositories (including WAL), PII redactor, and the ingest use case. It then starts an HTTP server to receive log events and a background health check for Redis with WAL replay.\n- Definitions in the File:\n  - Functions:\n    - `main()`: Main function.\n      - Description:\n        1. Loads application configuration using `config.Load()`.\n        2. Initializes a structured logger using `logger.New()`.\n        3. Establishes connections to PostgreSQL (`database/sql`) and Redis (`github.com/redis/go-redis/v9`), logging a warning if Redis is initially unavailable.\n        4. Initializes a `wal.NewWALRepository` for local persistence.\n        5. Creates `postgres.NewAPIKeyRepository` and `redisrepo.NewLogRepository` (configured with the WAL for buffering).\n        6. Starts a background goroutine for Redis health checking and WAL replay using `redisRepo.StartHealthCheck`.\n        7. Initializes a `pii.NewRedactor` with fields to redact from configuration.\n        8. Instantiates `usecase.NewIngestLogUseCase` with the Redis repository and PII redactor.\n        9. Configures and starts an HTTP server using `api.NewRouter` to handle incoming log ingestion requests.\n        10. Sets up a graceful shutdown mechanism for the HTTP server using `context` and `os.Signal` (SIGINT, SIGTERM) with a timeout.\n- Notable Patterns or Logic:\n  - Application entry point (`main` function).\n  - Dependency injection for services (repositories, use cases, redactor).\n  - Graceful shutdown handling for an HTTP server using `context` and `os.Signal`.\n  - Background goroutine for health checks and recovery (WAL replay).\n  - Initialization of multiple layers: config, logger, database, Redis, WAL, PII, use case, API router.",
  "go.mod": "- File Path: `go.mod`\n- High-Level Purpose: This file defines the Go module path and manages the direct and indirect dependencies required for the `github.com/user/log-ingestor` project.\n- Definitions in the File:\n  - Module: `github.com/user/log-ingestor`\n  - Go Version: `1.21`\n  - Direct Dependencies:\n    - `github.com/caarlos0/env/v10 v10.0.0`: Used for parsing environment variables into Go structs.\n    - `github.com/google/uuid v1.6.0`: Used for generating universally unique identifiers.\n    - `github.com/joho/godotenv v1.5.1`: Used for loading environment variables from `.env` files.\n    - `github.com/lib/pq v1.10.9`: PostgreSQL database driver.\n    - `github.com/redis/go-redis/v9 v9.5.1`: Redis client library.\n  - Indirect Dependencies:\n    - `github.com/cespare/xxhash/v2 v2.2.0`\n    - `github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f`\n- Notable Patterns or Logic:\n  - Go Module definition for dependency management.\n",
  "internal/adapter/api/handler/ingest_handler.go": "- File Path: `internal/adapter/api/handler/ingest_handler.go`\n- High-Level Purpose: This file defines an HTTP handler responsible for receiving and processing incoming log ingestion requests, supporting both single JSON and NDJSON (Newline Delimited JSON) formats.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `IngestHandler` (struct): An HTTP handler that processes log ingestion requests.\n      - Fields:\n        - `useCase` (`*usecase.IngestLogUseCase`): The use case responsible for the business logic of log ingestion.\n        - `logger` (`*slog.Logger`): A structured logger instance.\n        - `maxEventSize` (`int64`): The maximum allowed size for an incoming request body.\n  - Functions:\n    - `NewIngestHandler(uc *usecase.IngestLogUseCase, logger *slog.Logger, maxEventSize int64) *IngestHandler`: Public function.\n      - Description: Constructor for `IngestHandler`, initializing it with the ingest use case, logger, and the maximum event size.\n    - `(*IngestHandler) ServeHTTP(w http.ResponseWriter, r *http.Request)`: Public method.\n      - Description: Implements the `http.Handler` interface. It validates the request method (must be POST), enforces a maximum request body size, and dispatches the request to either `handleSingleJSON` or `handleNDJSON` based on the `Content-Type` header. It handles various HTTP errors such as unsupported media type, payload too large, and bad requests.\n    - `(*IngestHandler) handleSingleJSON(ctx context.Context, body io.Reader) error`: Internal method.\n      - Description: Reads a single JSON log event from the request body, unmarshals it into a `domain.LogEvent`, stores the raw event payload, and then passes it to the `IngestLogUseCase` for processing.\n    - `(*IngestHandler) handleNDJSON(ctx context.Context, body io.Reader) error`: Internal method.\n      - Description: Reads the request body line by line, treating each line as a separate JSON log event. It unmarshals each line, stores the raw event, and calls the `IngestLogUseCase` for each. It logs warnings for unmarshalling errors and errors for ingestion failures, but continues processing subsequent lines.\n- Notable Patterns or Logic:\n  - HTTP Handler implementation (`http.Handler` interface).\n  - Content-Type based request routing.\n  - Request body size limiting using `http.MaxBytesReader`.\n  - Processing of Newline Delimited JSON (NDJSON) streams.\n",
  "internal/adapter/api/middleware/auth.go": "- File Path: `internal/adapter/api/middleware/auth.go`\n- High-Level Purpose: This file defines an HTTP middleware for authenticating incoming requests by validating an API key provided in the `X-API-Key` header.\n- Definitions in the File:\n  - Constants:\n    - `APIKeyHeader` (string): \"X-API-Key\". Specifies the HTTP header name for the API key.\n  - Functions:\n    - `Auth(repo domain.APIKeyRepository, logger *slog.Logger) func(http.Handler) http.Handler`: Public function.\n      - Description: A middleware factory that returns an `http.Handler` function. It extracts the API key from the request header, uses the provided `APIKeyRepository` to validate it, and either allows the request to proceed or responds with an `Unauthorized` or `Internal Server Error` status.\n- Notable Patterns or Logic:\n  - HTTP Middleware pattern for request interception and processing.\n  - Dependency injection for the API key repository and logger.\n",
  "internal/adapter/api/router.go": "- File Path: `internal/adapter/api/router.go`\n- High-Level Purpose: This file is responsible for configuring and setting up the main HTTP router for the log ingest service, defining routes, associating them with handlers, and applying middleware.\n- Definitions in the File:\n  - Functions:\n    - `NewRouter(cfg *config.Config, logger *slog.Logger, apiKeyRepo domain.APIKeyRepository, ingestUseCase *usecase.IngestLogUseCase) http.Handler`: Public function.\n      - Description: Creates and configures an `http.ServeMux`. It initializes an `IngestHandler` and applies an `Auth` middleware (for API key validation) to the `POST /ingest` route. It also defines a simple `/health` check endpoint.\n- Notable Patterns or Logic:\n  - HTTP Router setup using `http.ServeMux`.\n  - Middleware chain application for request processing (e.g., authentication).\n  - Dependency injection for handlers and middleware.\n",
  "internal/adapter/pii/redactor.go": "- File Path: `internal/adapter/pii/redactor.go`\n- High-Level Purpose: This file defines a `Redactor` component responsible for identifying and replacing sensitive (PII) fields within the JSON `Metadata` of `LogEvent` objects with a placeholder.\n- Definitions in the File:\n  - Constants:\n    - `RedactedPlaceholder` (string): \"[REDACTED]\". The string used to replace redacted PII values.\n  - Classes / Structs / Interfaces:\n    - `Redactor` (struct): Manages the redaction of specified PII fields from log event metadata.\n      - Fields:\n        - `fieldsToRedact` (map[string]struct{}): A set of field names whose values should be redacted.\n        - `logger` (*slog.Logger): Structured logger instance.\n  - Functions:\n    - `NewRedactor(fields []string, logger *slog.Logger) *Redactor`: Public function.\n      - Description: Constructor for `Redactor`, initializing it with a list of field names to be redacted and a logger. It converts the list of fields into a map for efficient lookups.\n    - `(*Redactor) Redact(event *domain.LogEvent) error`: Public method.\n      - Description: Modifies the provided `LogEvent` in place. It unmarshals the `Metadata` field (expected to be JSON), iterates through the configured `fieldsToRedact`, and replaces any matching field values with `RedactedPlaceholder`. If any redaction occurs, it sets `event.PIIRedacted` to `true` and remarshals the modified metadata back into `event.Metadata`. It logs warnings or errors if JSON processing fails.\n- Notable Patterns or Logic:\n  - Data transformation/processing component.\n  - Dynamic JSON field manipulation using `encoding/json` for unmarshalling and marshalling.\n  - In-place modification of a domain object (`LogEvent`).",
  "internal/adapter/repository/postgres/apikey_repository.go": "- File Path: `internal/adapter/repository/postgres/apikey_repository.go`\n- High-Level Purpose: This file provides a PostgreSQL-backed implementation of the `domain.APIKeyRepository` interface, featuring an in-memory, time-based cache to optimize API key validation performance.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `cacheEntry` (struct): Represents a single entry in the API key cache.\n      - Fields:\n        - `isValid` (bool): Indicates if the API key is valid.\n        - `expiresAt` (time.Time): The timestamp when this cache entry expires.\n    - `APIKeyRepository` (struct): Implements `domain.APIKeyRepository` for PostgreSQL.\n      - Fields:\n        - `db` (*sql.DB): Database connection pool.\n        - `logger` (*slog.Logger): Structured logger instance.\n        - `cache` (map[string]cacheEntry): In-memory cache for API key validation results.\n        - `mu` (sync.RWMutex): Read-write mutex for thread-safe cache access.\n        - `cacheTTL` (time.Duration): Time-to-live for cache entries.\n  - Functions:\n    - `NewAPIKeyRepository(db *sql.DB, logger *slog.Logger, cacheTTL time.Duration) *APIKeyRepository`: Public function.\n      - Description: Constructor for `APIKeyRepository`, initializing it with a database connection, logger, and the desired cache TTL.\n    - `(*APIKeyRepository) IsValid(ctx context.Context, key string) (bool, error)`: Public method.\n      - Description: Checks if an API key is valid. It first attempts to retrieve the validation status from the in-memory cache. If the key is not found or the cache entry has expired, it queries the PostgreSQL database, updates the cache with the new validation status and expiration, and then returns the result. It uses a read-write mutex to ensure thread safety during cache operations.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for data access.\n  - Read-through caching mechanism with a configurable time-to-live (TTL).\n  - Concurrency control using `sync.RWMutex` for safe access to the shared cache.\n  - Database interaction using `database/sql` for PostgreSQL.\n",
  "internal/adapter/repository/postgres/log_repository.go": "- File Path: `internal/adapter/repository/postgres/log_repository.go`\n- High-Level Purpose: This file provides a PostgreSQL-backed implementation for the \"sink\" part of the `domain.LogRepository` interface, specifically designed for high-performance batch writing of log events using PostgreSQL's `COPY` protocol and idempotent upsert logic.\n- Definitions in the File:\n  - Constants:\n    - `logsTableName` (string): \"logs\". The name of the PostgreSQL table where logs are stored.\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (struct): Implements the `domain.LogRepository` interface for PostgreSQL.\n      - Fields:\n        - `db` (*sql.DB): Database connection pool.\n        - `logger` (*slog.Logger): Structured logger instance.\n  - Functions:\n    - `NewLogRepository(db *sql.DB, logger *slog.Logger) *LogRepository`: Public function.\n      - Description: Constructor for `LogRepository`, initializing it with a database connection and logger.\n    - `(*LogRepository) WriteLogBatch(ctx context.Context, events []domain.LogEvent) error`: Public method.\n      - Description: Writes a batch of log events to PostgreSQL. It uses a database transaction, creates a temporary table, and leverages `pq.CopyIn` for efficient bulk data transfer. After staging, it performs an `INSERT ... ON CONFLICT (event_id) DO UPDATE` (upsert) from the temporary table into the main `logs` table, ensuring idempotency.\n    - `errNotImplemented` (var): Internal variable.\n      - Description: An error indicating that a method is not implemented for this specific repository type.\n    - `(*LogRepository) BufferLog(ctx context.Context, event domain.LogEvent) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not responsible for buffering.\n    - `(*LogRepository) ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]domain.LogEvent, error)`: Public method.\n      - Description: Returns `nil, errNotImplemented` as this repository is not responsible for reading from a buffer.\n    - `(*LogRepository) AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not responsible for acknowledging buffered messages.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for data sinking.\n  - High-performance bulk inserts using PostgreSQL's `COPY` protocol.\n  - Idempotent upsert logic using `ON CONFLICT DO UPDATE`.\n  - Transaction management for batch operations.\n  - Partial interface implementation, indicating a specialized role (sink only).\n",
  "internal/adapter/repository/redis/log_repository.go": "- File Path: `internal/adapter/repository/redis/log_repository.go`\n- High-Level Purpose: This file implements the `domain.LogRepository` interface using Redis Streams for buffering log events. It also incorporates a Write-Ahead Log (WAL) for resilience during Redis outages and includes health check mechanisms with automatic WAL replay.\n- Definitions in the File:\n  - Constants:\n    - `logStreamKey` (string): \"log_events\". The Redis Stream key used for log events.\n  - Variables:\n    - `errNotImplemented` (error): An error indicating a method is not implemented for this repository type.\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (struct): Implements `domain.LogRepository` for Redis Streams with WAL failover.\n      - Fields:\n        - `client` (*redis.Client): Redis client instance.\n        - `logger` (*slog.Logger): Structured logger.\n        - `wal` (`domain.WALRepository`): Optional WAL repository for persistence during Redis unavailability.\n        - `dlqStreamKey` (string): The Redis Stream key for the Dead-Letter Queue.\n        - `isAvailable` (atomic.Bool): Atomic boolean indicating Redis connectivity status.\n  - Functions:\n    - `NewLogRepository(client *redis.Client, logger *slog.Logger, group, consumer, dlqStreamKey string, wal domain.WALRepository) (*LogRepository, error)`: Public function.\n      - Description: Constructor for `LogRepository`. Initializes the Redis client, logger, WAL, and DLQ stream key. It attempts to set up the consumer group on startup and assumes Redis is available initially.\n    - `(*LogRepository) StartHealthCheck(ctx context.Context, interval time.Duration)`: Public method.\n      - Description: Starts a background goroutine that periodically pings Redis. If Redis becomes unavailable, it updates `isAvailable`. If Redis recovers, it attempts to replay events from the WAL. This is skipped if WAL is not configured.\n    - `(*LogRepository) ReplayWAL(ctx context.Context) error`: Public method.\n      - Description: Reads all events from the configured WAL and buffers them into Redis. Upon successful replay, it truncates the WAL.\n    - `(*LogRepository) setupConsumerGroup(ctx context.Context, group string) error`: Internal method.\n      - Description: Creates a Redis consumer group for the `logStreamKey` if it doesn't already exist.\n    - `(*LogRepository) BufferLog(ctx context.Context, event domain.LogEvent) error`: Public method.\n      - Description: Buffers a log event to the Redis Stream. If Redis is unavailable (or becomes unavailable during the write), it falls back to writing the event to the WAL if configured.\n    - `(*LogRepository) bufferLogToRedis(ctx context.Context, event domain.LogEvent) error`: Internal method.\n      - Description: Marshals a log event to JSON and adds it to the Redis Stream using `XADD`.\n    - `(*LogRepository) ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]domain.LogEvent, error)`: Public method.\n      - Description: Reads a batch of log events from the Redis Stream for a given consumer group and consumer using `XREADGROUP`. It unmarshals the payload and attaches the `StreamMessageID`.\n    - `(*LogRepository) AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Public method.\n      - Description: Acknowledges a list of message IDs in the Redis Stream for a given consumer group using `XACK`.\n    - `(*LogRepository) MoveToDLQ(ctx context.Context, events []domain.LogEvent) error`: Public method.\n      - Description: Moves a batch of log events to a Dead-Letter Queue (DLQ) Redis Stream. It marshals events and adds them to the DLQ stream with additional metadata about their origin.\n    - `(*LogRepository) WriteLogBatch(ctx context.Context, events []domain.LogEvent) error`: Public method.\n      - Description: Returns `errNotImplemented` as this repository is not intended for batch writing to a final sink.\n    - `isRedisBusyGroupError(err error) bool`: Internal function.\n      - Description: Checks if a given error is the \"BUSYGROUP Consumer Group name already exists\" error from Redis.\n    - `isNetworkError(err error) bool`: Internal function.\n      - Description: Checks if a given error is a network-related error, including `net.Error`, `redis.ErrClosed`, `context.Canceled`, or `context.DeadlineExceeded`.\n- Notable Patterns or Logic:\n  - Repository pattern implementation for a message buffer.\n  - Redis Streams for durable message queuing and consumer group management.\n  - Write-Ahead Log (WAL) as a failover mechanism for Redis unavailability.\n  - Health check and automatic WAL replay upon Redis recovery.\n  - Dead-Letter Queue (DLQ) implementation for failed events.\n  - Atomic operations for managing Redis availability status.\n",
  "internal/adapter/repository/wal/wal_repository.go": "- File Path: `internal/adapter/repository/wal/wal_repository.go`\n- High-Level Purpose: This file provides a file-based Write-Ahead Log (WAL) implementation for durable storage of log events, designed to handle temporary failures of primary storage systems. It supports segment rotation, replay, and truncation.\n- Definitions in the File:\n  - Constants:\n    - `segmentPrefix` (string): \"segment-\". Prefix for WAL segment filenames.\n    - `filePerm` (os.FileMode): 0644. Default file permissions for WAL segments.\n  - Classes / Structs / Interfaces:\n    - `WALRepository` (struct): Implements a file-based Write-Ahead Log.\n      - Fields:\n        - `dir` (string): Directory path where WAL segments are stored.\n        - `maxSegmentSize` (int64): Maximum size for a single WAL segment file before rotation.\n        - `maxTotalSize` (int64): Maximum total disk space allowed for all WAL segments.\n        - `logger` (*slog.Logger): Structured logger.\n        - `mu` (sync.Mutex): Mutex for protecting concurrent access to WAL operations.\n        - `currentSegment` (*os.File): File handle for the currently active WAL segment.\n        - `currentSize` (int64): Current size of the active WAL segment.\n  - Functions:\n    - `NewWALRepository(dir string, maxSegmentSize, maxTotalSize int64, logger *slog.Logger) (*WALRepository, error)`: Public function.\n      - Description: Constructor for `WALRepository`. Initializes the WAL directory, size limits, and logger. It attempts to open the latest existing segment or create a new one.\n    - `(*WALRepository) Write(ctx context.Context, event domain.LogEvent) error`: Public method.\n      - Description: Marshals a log event to JSON, appends a newline, and writes it to the current WAL segment. It checks for `maxTotalSize` before writing and rotates the segment if `maxSegmentSize` is reached.\n    - `(*WALRepository) Replay(ctx context.Context, handler func(event domain.LogEvent) error) error`: Public method.\n      - Description: Reads all events from all WAL segments in chronological order. For each event, it calls the provided `handler` function. It closes the current segment before replay and re-opens a new one after.\n    - `(*WALRepository) Truncate(ctx context.Context) error`: Public method.\n      - Description: Closes the current segment and removes all WAL segment files from the directory. It then opens a new, empty segment.\n    - `(*WALRepository) rotate() error`: Internal method.\n      - Description: Closes the current WAL segment (if open), generates a new segment filename based on the current timestamp, creates and opens the new file, and resets `currentSize`.\n    - `(*WALRepository) openLatestSegment() error`: Internal method.\n      - Description: Identifies the latest WAL segment file, opens it for appending, and sets `currentSize` to its current size. If no segments exist, it calls `rotate` to create a new one. If the latest segment is already full, it also calls `rotate`.\n    - `(*WALRepository) getSortedSegments() ([]string, error)`: Internal method.\n      - Description: Reads the WAL directory, filters for segment files, and returns their full paths sorted chronologically.\n    - `(*WALRepository) calculateTotalSize() (int64, error)`: Internal method.\n      - Description: Calculates the total disk space occupied by all WAL segment files.\n    - `(*WALRepository) Close() error`: Public method.\n      - Description: Closes the currently active WAL segment file, ensuring all buffered writes are flushed to disk.\n- Notable Patterns or Logic:\n  - Write-Ahead Log (WAL) implementation for durability and crash recovery.\n  - Segment-based storage with configurable `maxSegmentSize` and `maxTotalSize`.\n  - File system operations for managing log files (`os.MkdirAll`, `os.OpenFile`, `os.Remove`, `os.ReadDir`, `os.Stat`).\n  - Concurrency control using `sync.Mutex` for safe file access.\n  - Line-by-line processing of JSON events during replay using `bufio.Scanner`.\n",
  "internal/domain/log.go": "- File Path: `internal/domain/log.go`\n- High-Level Purpose: This file defines the `LogEvent` struct, which serves as the core data model for representing a single log event within the application's domain.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `LogEvent` (struct): Represents a single log event with various attributes.\n      - Fields:\n        - `ID` (string): Unique identifier for the log event.\n        - `ReceivedAt` (time.Time): Timestamp when the event was received by the system.\n        - `EventTime` (time.Time): Original timestamp of the event.\n        - `Source` (string): Origin of the log event (e.g., service name).\n        - `Level` (string): Log level (e.g., \"info\", \"error\").\n        - `Message` (string): The main log message.\n        - `Metadata` (json.RawMessage): Arbitrary JSON metadata associated with the event.\n        - `RawEvent` (json.RawMessage): The original raw payload of the event (not serialized for output).\n        - `PIIRedacted` (bool): Flag indicating if PII has been redacted from the event.\n        - `StreamMessageID` (string): Transient field for Redis Stream message ID (not serialized for output).\n- Notable Patterns or Logic:\n  - Domain model definition for log events.\n  - Use of `json.RawMessage` for flexible metadata storage.\n",
  "internal/domain/repository.go": "- File Path: `internal/domain/repository.go`\n- High-Level Purpose: This file defines the core interfaces for various repositories within the log ingestor application, establishing contracts for log event management, API key validation, and Write-Ahead Log operations.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `LogRepository` (interface): Defines methods for buffering, reading, writing, acknowledging, and moving log events to a DLQ.\n      - Methods:\n        - `BufferLog(ctx context.Context, event LogEvent) error`: Adds a single log event to a durable buffer.\n        - `ReadLogBatch(ctx context.Context, group, consumer string, count int) ([]LogEvent, error)`: Reads a batch of log events from the buffer for a consumer group.\n        - `WriteLogBatch(ctx context.Context, events []LogEvent) error`: Writes a batch of log events to final persistent storage.\n        - `AcknowledgeLogs(ctx context.Context, group string, messageIDs ...string) error`: Marks log events as processed in the buffer.\n        - `MoveToDLQ(ctx context.Context, events []LogEvent) error`: Moves events to a Dead-Letter Queue.\n    - `APIKeyRepository` (interface): Defines the contract for validating API keys.\n      - Methods:\n        - `IsValid(ctx context.Context, key string) (bool, error)`: Checks if an API key is valid.\n    - `WALRepository` (interface): Defines the contract for a Write-Ahead Log.\n      - Methods:\n        - `Write(ctx context.Context, event LogEvent) error`: Writes a single event to the WAL.\n        - `Replay(ctx context.Context, handler func(event LogEvent) error) error`: Reads all events from the WAL and processes them with a handler.\n        - `Truncate(ctx context.Context) error`: Removes all events/segments from the WAL.\n        - `Close() error`: Closes the WAL, ensuring resources are released.\n- Notable Patterns or Logic:\n  - Repository pattern for abstracting data access and persistence logic.\n  - Interface-driven design for loose coupling and testability.\n  - Defines the \"ports\" for the application's domain layer.\n",
  "internal/pkg/config/config.go": "- File Path: `internal/pkg/config/config.go`\n- High-Level Purpose: This file defines the application's configuration structure and provides a utility function to load these settings from environment variables, with support for `.env` files for local development.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `Config` (struct): Holds all application configuration parameters.\n      - Fields:\n        - `LogLevel` (string): Logging level (e.g., \"info\", \"debug\").\n        - `MaxEventSize` (int64): Maximum allowed size for an incoming log event (default 1MB).\n        - `WALPath` (string): Path for Write-Ahead Log files (default \"./wal\").\n        - `WALSegmentSize` (int64): Maximum size of a single WAL segment (default 100MB).\n        - `WALMaxDiskSize` (int64): Maximum total disk space for the WAL (default 1GB).\n        - `BackpressurePolicy` (string): Policy for handling backpressure (default \"block\").\n        - `RedisAddr` (string): Address of the Redis server (required).\n        - `RedisDLQStream` (string): Name of the Redis Dead-Letter Queue stream (default \"log_events_dlq\").\n        - `PostgresURL` (string): Connection URL for PostgreSQL (required).\n        - `APIKeyCacheTTL` (time.Duration): Time-to-live for API key cache entries (default 5m).\n        - `PIIRedactionFields` (string): Comma-separated list of fields to redact for PII (default \"email,password,credit_card,ssn\").\n        - `IngestServerAddr` (string): Address for the HTTP ingest server to listen on (default \":8080\").\n        - `ConsumerRetryCount` (int): Number of retries for consumer processing (default 3).\n        - `ConsumerRetryBackoff` (time.Duration): Initial backoff duration for consumer retries (default 1s).\n  - Functions:\n    - `Load() (*Config, error)`: Public function.\n      - Description: Loads configuration from environment variables. It first attempts to load a `.env` file (for local development) and then parses environment variables into the `Config` struct using `github.com/caarlos0/env`.\n- Notable Patterns or Logic:\n  - Centralized configuration management.\n  - Environment variable parsing using `github.com/caarlos0/env`.\n  - Support for `.env` files for development convenience using `github.com/joho/godotenv`.\n",
  "internal/pkg/logger/logger.go": "- File Path: `internal/pkg/logger/logger.go`\n- High-Level Purpose: This file provides a utility function to create and configure a structured logger using Go's `slog` package.\n- Definitions in the File:\n  - Functions:\n    - `New(level string) *slog.Logger`: Public function.\n      - Description: Creates and returns a new `slog.Logger` instance. It configures the logger to output JSON format to standard output and sets the logging level based on the provided string (e.g., \"debug\", \"info\", \"warn\", \"error\"). Defaults to \"info\" if an unknown level is provided.\n- Notable Patterns or Logic:\n  - Centralized logger initialization.\n  - Structured logging setup using `slog`.\n",
  "internal/usecase/ingest_log.go": "- File Path: `internal/usecase/ingest_log.go`\n- High-Level Purpose: This file defines the `IngestLogUseCase`, which encapsulates the business logic for processing and buffering log events, including enrichment, PII redaction, and interaction with the log repository.\n- Definitions in the File:\n  - Classes / Structs / Interfaces:\n    - `IngestLogUseCase` (struct): Handles the core business logic for ingesting a log event.\n      - Fields:\n        - `repo` (`domain.LogRepository`): An interface for buffering log events.\n        - `redactor` (`*pii.Redactor`): A component responsible for redacting PII from log events.\n        - `logger` (`*slog.Logger`): A structured logger instance.\n  - Functions:\n    - `NewIngestLogUseCase(repo domain.LogRepository, redactor *pii.Redactor, logger *slog.Logger) *IngestLogUseCase`: Public function.\n      - Description: Constructor for `IngestLogUseCase`, initializing it with the necessary repository, PII redactor, and logger.\n    - `(*IngestLogUseCase) Ingest(ctx context.Context, event *domain.LogEvent) error`: Public method.\n      - Description: Validates, enriches, redacts, and buffers a log event. It sets `ReceivedAt` and generates an `ID` if missing, then calls the `pii.Redactor` to redact sensitive information. Finally, it uses the `domain.LogRepository` to buffer the processed event. It logs warnings for redaction failures and errors for buffering failures.\n- Notable Patterns or Logic:\n  - Use Case pattern for encapsulating business logic.\n  - Dependency injection for external services (repository, redactor, logger).\n  - In-place modification of the `domain.LogEvent` object.\n",
  "internal/usecase/process_logs.go": "- File Path: `internal/usecase/process_logs.go`\n- High-Level Purpose: This file defines the `ProcessLogsUseCase`, which orchestrates the end-to-end processing of log events by reading them from a buffer, attempting to write them to a persistent sink with retries, and managing acknowledgments or moving failed events to a Dead-Letter Queue.\n- Definitions in the File:\n  - Constants:\n    - `defaultBatchSize` (int): 1000. The default number of log events to read in a single batch.\n  - Classes / Structs / Interfaces:\n    - `ProcessLogsUseCase` (struct): Orchestrates the processing of log events from buffer to sink.\n      - Fields:\n        - `bufferRepo` (`domain.LogRepository`): Repository for reading from the log buffer (e.g., Redis Stream).\n        - `sinkRepo` (`domain.LogRepository`): Repository for writing to the final persistent storage (e.g., PostgreSQL).\n        - `logger` (*slog.Logger): Structured logger.\n        - `group` (string): Consumer group name for the buffer.\n        - `consumer` (string): Unique consumer name.\n        - `retryCount` (int): Number of retries for writing to the sink.\n        - `retryBackoff` (time.Duration): Initial backoff duration for retries.\n  - Functions:\n    - `NewProcessLogsUseCase(bufferRepo, sinkRepo domain.LogRepository, logger *slog.Logger, group, consumer string, retryCount int, retryBackoff time.Duration) *ProcessLogsUseCase`: Public function.\n      - Description: Constructor for `ProcessLogsUseCase`, initializing it with buffer and sink repositories, logger, consumer group/name, and retry configuration.\n    - `(*ProcessLogsUseCase) ProcessBatch(ctx context.Context) (int, error)`: Public method.\n      - Description: Reads a batch of logs from the `bufferRepo`. It then attempts to write these logs to the `sinkRepo` using a retry mechanism. If writing fails after all retries, it moves the events to a Dead-Letter Queue via the `bufferRepo`. Finally, it acknowledges successfully processed or DLQ'd events in the `bufferRepo`.\n    - `(*ProcessLogsUseCase) writeWithRetry(ctx context.Context, events []domain.LogEvent) error`: Internal method.\n      - Description: Attempts to write a batch of log events to the `sinkRepo` with a configurable number of retries and exponential backoff between attempts.\n- Notable Patterns or Logic:\n  - Use Case pattern for orchestrating complex business logic.\n  - Dependency injection for buffer and sink repositories.\n  - Retry mechanism with exponential backoff for resilient writes to the sink.\n  - Dead-Letter Queue (DLQ) integration for handling persistently failing events.\n  - Consumer group pattern for distributed log processing.\n"
}