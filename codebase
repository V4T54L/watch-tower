{
  "cmd/consumer/main.go": "package main\n\nimport (\n\t\"log/slog\"\n\t\"os\"\n\n\t\"github.com/user/log-ingestor/internal/pkg/config\"\n\t\"github.com/user/log-ingestor/internal/pkg/logger\"\n)\n\nfunc main() {\n\tcfg, err := config.Load()\n\tif err != nil {\n\t\tslog.Error(\"failed to load configuration\", \"error\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlog := logger.New(cfg.LogLevel)\n\tlog.Info(\"starting consumer worker...\")\n\n\t// TODO: Initialize and run consumer logic\n\t// - Connect to Redis\n\t// - Start consumer group processing loop\n\t// - Connect to PostgreSQL\n\t// - Setup signal handling for graceful shutdown\n\n\tlog.Info(\"consumer worker stopped\")\n}\n",
  "cmd/ingest/main.go": "package main\n\nimport (\n\t\"log/slog\"\n\t\"os\"\n\n\t\"github.com/user/log-ingestor/internal/pkg/config\"\n\t\"github.com/user/log-ingestor/internal/pkg/logger\"\n)\n\nfunc main() {\n\tcfg, err := config.Load()\n\tif err != nil {\n\t\tslog.Error(\"failed to load configuration\", \"error\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlog := logger.New(cfg.LogLevel)\n\tlog.Info(\"starting ingest gateway...\")\n\n\t// TODO: Initialize and run ingest server\n\t// - Initialize repositories (Redis, WAL, PostgreSQL for API keys)\n\t// - Initialize use cases\n\t// - Setup HTTP router and handlers\n\t// - Start HTTP server\n\t// - Setup signal handling for graceful shutdown\n\n\tlog.Info(\"ingest gateway stopped\")\n}\n",
  "go.mod": "module github.com/user/log-ingestor\n\ngo 1.21\n\nrequire (\n\tgithub.com/caarlos0/env/v10 v10.0.0\n\tgithub.com/joho/godotenv v1.5.1\n)\n",
  "internal/adapter/api/middleware/auth.go": "package middleware\n\nimport (\n\t\"log/slog\"\n\t\"net/http\"\n\n\t\"github.com/user/log-ingestor/internal/domain\"\n)\n\nconst APIKeyHeader = \"X-API-Key\"\n\n// Auth is a middleware factory that returns a new authentication middleware.\n// It checks for a valid API key in the X-API-Key header.\nfunc Auth(repo domain.APIKeyRepository, logger *slog.Logger) func(http.Handler) http.Handler {\n\treturn func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tapiKey := r.Header.Get(APIKeyHeader)\n\t\t\tif apiKey == \"\" {\n\t\t\t\tlogger.Warn(\"API key missing from request\", \"remote_addr\", r.RemoteAddr)\n\t\t\t\thttp.Error(w, \"Unauthorized: API key required\", http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tisValid, err := repo.IsValid(r.Context(), apiKey)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Error(\"failed to validate API key\", \"error\", err)\n\t\t\t\thttp.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !isValid {\n\t\t\t\tlogger.Warn(\"invalid API key provided\", \"remote_addr\", r.RemoteAddr)\n\t\t\t\thttp.Error(w, \"Unauthorized: Invalid API key\", http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tnext.ServeHTTP(w, r)\n\t\t})\n\t}\n}\n",
  "internal/adapter/pii/redactor.go": "package pii\n\nimport (\n\t\"encoding/json\"\n\t\"log/slog\"\n\n\t\"github.com/user/log-ingestor/internal/domain\"\n)\n\nconst RedactedPlaceholder = \"[REDACTED]\"\n\n// Redactor is responsible for redacting sensitive information from log events.\ntype Redactor struct {\n\tfieldsToRedact map[string]struct{} // Use a map for O(1) lookups\n\tlogger         *slog.Logger\n}\n\n// NewRedactor creates a new Redactor instance with a given set of fields to redact.\nfunc NewRedactor(fields []string, logger *slog.Logger) *Redactor {\n\tfieldSet := make(map[string]struct{}, len(fields))\n\tfor _, field := range fields {\n\t\tfieldSet[field] = struct{}{}\n\t}\n\treturn \u0026Redactor{\n\t\tfieldsToRedact: fieldSet,\n\t\tlogger:         logger,\n\t}\n}\n\n// Redact modifies the LogEvent in place to remove PII from its metadata.\n// It returns an error if JSON processing fails.\nfunc (r *Redactor) Redact(event *domain.LogEvent) error {\n\tif len(r.fieldsToRedact) == 0 || len(event.Metadata) == 0 {\n\t\treturn nil\n\t}\n\n\tvar metadata map[string]interface{}\n\tif err := json.Unmarshal(event.Metadata, \u0026metadata); err != nil {\n\t\tr.logger.Warn(\"failed to unmarshal metadata for PII redaction\", \"error\", err, \"event_id\", event.ID)\n\t\t// We can't process it, so we leave it as is.\n\t\treturn err\n\t}\n\n\tredacted := false\n\tfor field := range r.fieldsToRedact {\n\t\tif _, ok := metadata[field]; ok {\n\t\t\tmetadata[field] = RedactedPlaceholder\n\t\t\tredacted = true\n\t\t}\n\t}\n\n\tif redacted {\n\t\tevent.PIIRedacted = true\n\t\tmodifiedMetadata, err := json.Marshal(metadata)\n\t\tif err != nil {\n\t\t\tr.logger.Error(\"failed to marshal modified metadata after PII redaction\", \"error\", err, \"event_id\", event.ID)\n\t\t\t// This is a more serious internal error.\n\t\t\treturn err\n\t\t}\n\t\tevent.Metadata = modifiedMetadata\n\t}\n\n\treturn nil\n}\n",
  "internal/adapter/repository/postgres/apikey_repository.go": "package postgres\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"log/slog\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype cacheEntry struct {\n\tisValid   bool\n\texpiresAt time.Time\n}\n\n// APIKeyRepository implements the domain.APIKeyRepository interface using PostgreSQL\n// as the source of truth and an in-memory, time-based cache.\ntype APIKeyRepository struct {\n\tdb       *sql.DB\n\tlogger   *slog.Logger\n\tcache    map[string]cacheEntry\n\tmu       sync.RWMutex\n\tcacheTTL time.Duration\n}\n\n// NewAPIKeyRepository creates a new instance of the PostgreSQL API key repository.\nfunc NewAPIKeyRepository(db *sql.DB, logger *slog.Logger, cacheTTL time.Duration) *APIKeyRepository {\n\treturn \u0026APIKeyRepository{\n\t\tdb:       db,\n\t\tlogger:   logger,\n\t\tcache:    make(map[string]cacheEntry),\n\t\tcacheTTL: cacheTTL,\n\t}\n}\n\n// IsValid checks if an API key is valid. It first checks a local cache and falls\n// back to the database if the key is not found or the cache entry has expired.\nfunc (r *APIKeyRepository) IsValid(ctx context.Context, key string) (bool, error) {\n\t// 1. Check cache with a read lock\n\tr.mu.RLock()\n\tentry, found := r.cache[key]\n\tif found \u0026\u0026 time.Now().Before(entry.expiresAt) {\n\t\tr.mu.RUnlock()\n\t\treturn entry.isValid, nil\n\t}\n\tr.mu.RUnlock()\n\n\t// 2. If not in cache or expired, query DB and update cache with a write lock\n\tr.mu.Lock()\n\tdefer r.mu.Unlock()\n\n\t// 2a. Double-check cache in case another goroutine populated it while waiting for the lock\n\tentry, found = r.cache[key]\n\tif found \u0026\u0026 time.Now().Before(entry.expiresAt) {\n\t\treturn entry.isValid, nil\n\t}\n\n\t// 3. Query the database\n\tvar isValid bool\n\t// A key is valid if it exists, is active, and has not expired.\n\tquery := `SELECT EXISTS(SELECT 1 FROM api_keys WHERE key = $1 AND is_active = true AND (expires_at IS NULL OR expires_at \u003e NOW()))`\n\terr := r.db.QueryRowContext(ctx, query, key).Scan(\u0026isValid)\n\tif err != nil {\n\t\tr.logger.Error(\"failed to validate API key in database\", \"error\", err)\n\t\t// Don't cache errors, let the next request retry from the DB\n\t\treturn false, err\n\t}\n\n\t// 4. Update cache\n\tr.cache[key] = cacheEntry{\n\t\tisValid:   isValid,\n\t\texpiresAt: time.Now().Add(r.cacheTTL),\n\t}\n\n\treturn isValid, nil\n}\n```",
  "internal/domain/log.go": "package domain\n\nimport (\n\t\"encoding/json\"\n\t\"time\"\n)\n\n// LogEvent represents the canonical structure of a log event within the system.\ntype LogEvent struct {\n\tID          string          `json:\"event_id\"`\n\tReceivedAt  time.Time       `json:\"received_at\"`\n\tEventTime   time.Time       `json:\"event_time\"`\n\tSource      string          `json:\"source,omitempty\"`\n\tLevel       string          `json:\"level,omitempty\"`\n\tMessage     string          `json:\"message\"`\n\tMetadata    json.RawMessage `json:\"metadata,omitempty\"`\n\tRawEvent    json.RawMessage `json:\"-\"` // The original raw event, not marshalled to the final sink\n\tPIIRedacted bool            `json:\"pii_redacted,omitempty\"`\n}\n",
  "internal/domain/repository.go": "package domain\n\nimport \"context\"\n\n// LogRepository defines the interface for buffering and sinking log events.\n// This abstracts away the specific implementations (e.g., Redis Streams, PostgreSQL).\ntype LogRepository interface {\n\t// BufferLog adds a single log event to the durable buffer.\n\tBufferLog(ctx context.Context, event LogEvent) error\n\n\t// ReadLogBatch reads a batch of log events from the buffer for a specific consumer.\n\tReadLogBatch(ctx context.Context, group, consumer string, count int) ([]LogEvent, error)\n\n\t// WriteLogBatch writes a batch of log events to the final structured sink.\n\tWriteLogBatch(ctx context.Context, events []LogEvent) error\n\n\t// AcknowledgeLogs marks a set of log events as successfully processed in the buffer.\n\tAcknowledgeLogs(ctx context.Context, group string, eventIDs ...string) error\n}\n\n// APIKeyRepository defines the interface for validating API keys.\ntype APIKeyRepository interface {\n\t// IsValid checks if the provided API key is valid and active.\n\t// Implementations should handle caching to reduce database load.\n\tIsValid(ctx context.Context, key string) (bool, error)\n}\n\n// WALRepository defines the interface for the Write-Ahead Log failover mechanism.\ntype WALRepository interface {\n\t// Write appends a log event to the local WAL file.\n\tWrite(ctx context.Context, event LogEvent) error\n\n\t// Replay reads events from the WAL and sends them to a handler function.\n\t// The handler is responsible for re-buffering the event (e.g., to Redis).\n\tReplay(ctx context.Context, handler func(event LogEvent) error) error\n\n\t// Truncate removes WAL segments that have been successfully replayed.\n\tTruncate(ctx context.Context) error\n}\n",
  "internal/pkg/config/config.go": "package config\n\nimport (\n\t\"time\"\n\n\t\"github.com/caarlos0/env/v10\"\n\t\"github.com/joho/godotenv\"\n)\n\n// Config holds all configuration for the application, loaded from environment variables.\ntype Config struct {\n\tLogLevel       string `env:\"LOG_LEVEL\" envDefault:\"info\"`\n\tMaxEventSize   int64  `env:\"MAX_EVENT_SIZE_BYTES\" envDefault:\"1048576\"` // 1MB\n\tWALSegmentSize int64  `env:\"WAL_SEGMENT_SIZE_BYTES\" envDefault:\"104857600\"` // 100MB\n\tWALMaxDiskSize int64  `env:\"WAL_MAX_DISK_SIZE_BYTES\" envDefault:\"1073741824\"` // 1GB\n\n\t// BackpressurePolicy defines how the ingest API behaves when internal buffers are full.\n\t// Supported values: \"block\", \"429\", \"drop\".\n\tBackpressurePolicy string `env:\"BACKPRESSURE_POLICY\" envDefault:\"429\"`\n\n\t// Redis configuration\n\tRedisAddr string `env:\"REDIS_ADDR,required\"`\n\n\t// PostgreSQL configuration\n\tPostgresURL string `env:\"POSTGRES_URL,required\"`\n\n\t// API Key Cache configuration\n\tAPIKeyCacheTTL time.Duration `env:\"API_KEY_CACHE_TTL\" envDefault:\"5m\"`\n}\n\n// Load parses environment variables into the Config struct.\n// It also loads a .env file if it exists, for local development.\nfunc Load() (*Config, error) {\n\t// Load .env file if it exists. This is useful for local development.\n\t// In production, environment variables should be set directly.\n\t_ = godotenv.Load()\n\n\tcfg := \u0026Config{}\n\tif err := env.Parse(cfg); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cfg, nil\n}\n",
  "internal/pkg/logger/logger.go": "package logger\n\nimport (\n\t\"log/slog\"\n\t\"os\"\n\t\"strings\"\n)\n\n// New creates and configures a new slog.Logger.\nfunc New(level string) *slog.Logger {\n\tvar logLevel slog.Level\n\n\tswitch strings.ToLower(level) {\n\tcase \"debug\":\n\t\tlogLevel = slog.LevelDebug\n\tcase \"info\":\n\t\tlogLevel = slog.LevelInfo\n\tcase \"warn\", \"warning\":\n\t\tlogLevel = slog.LevelWarn\n\tcase \"error\":\n\t\tlogLevel = slog.LevelError\n\tdefault:\n\t\tlogLevel = slog.LevelInfo\n\t}\n\n\topts := \u0026slog.HandlerOptions{\n\t\tLevel: logLevel,\n\t}\n\n\thandler := slog.NewJSONHandler(os.Stdout, opts)\n\tlogger := slog.New(handler)\n\n\treturn logger\n}\n```"
}